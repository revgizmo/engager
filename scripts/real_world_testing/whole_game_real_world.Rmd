---
title: "Whole Game: Real-World Workflow for Instructors"
author: "zoomstudentengagement package"
date: "`r Sys.Date()`"
output: rmarkdown::html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  warning = FALSE,
  message = FALSE
)
```

```{r load-packages}
library(zoomstudentengagement)
library(dplyr)
library(ggplot2)
library(readr)
library(tibble)
library(lubridate)
library(jsonlite)
```

# Whole Game: Real-World Workflow for Instructors

This document demonstrates the complete workflow for analyzing student engagement in Zoom sessions using your actual data. It's designed to work with the real-world testing environment.

## Prerequisites

Before starting this workflow:

1. **Run the setup script**: `./setup.sh`
2. **Add your data files**:
   - Put Zoom transcript files (`.transcript.vtt`) in `data/transcripts/`
   - Put your roster file (`roster.csv`) in `data/metadata/`
   - Put Zoom recordings list (`zoomus_recordings__*.csv`) in `data/metadata/`
   
   **Note**: The package processes `.transcript.vtt` files for engagement analysis. 
   `.cc.vtt` (closed captions) and `.txt` (chat) files are not processed.

## Step 1: Understanding Your Data

First, let's explore what data you have available:

## üîí **Privacy Testing Setup**

Before we begin the main workflow, let's test the privacy features to ensure they're working correctly. This is crucial for FERPA compliance and ethical use.

### **Testing Privacy Levels**

The package supports four privacy levels that control how names are handled:

1. **`ferpa_strict`**: Maximum privacy - masks all names including instructors
2. **`ferpa_standard`**: Standard privacy - masks student names, preserves instructor names
3. **`mask`**: Basic masking - masks student names, preserves instructor names
4. **`none`**: No masking - shows all names (use with extreme caution)

Let's test each privacy level:

```{r explore-data}
# Check what transcript files are available
transcript_files <- list.files(
  "data/transcripts",
  pattern = "\\.transcript\\.vtt$",
  full.names = TRUE,
  recursive = TRUE
)

cat("Available transcript files (.transcript.vtt):\n")
basename(transcript_files)

# Also check for other file types (for reference)
cc_files <- list.files(
  "data/transcripts",
  pattern = "\\.cc\\.vtt$",
  full.names = FALSE,
  recursive = TRUE
)

chat_files <- list.files(
  "data/transcripts",
  pattern = "\\.txt$",
  full.names = FALSE,
  recursive = TRUE
)

cat("\nOther file types found:\n")
if (length(cc_files) > 0) {
  cat("- Closed caption files (.cc.vtt):", paste(cc_files, collapse = ", "), "\n")
}
if (length(chat_files) > 0) {
  cat("- Chat files (.txt):", paste(chat_files, collapse = ", "), "\n")
}
cat("\nNote: Only .transcript.vtt files are processed for engagement analysis.\n")

# Check what metadata files are available
cat("\nAvailable metadata files:\n")
list.files("data/metadata")

# Check for specific file types
roster_files <- list.files("data/metadata", pattern = "roster\\.csv$", full.names = TRUE)
zoom_files <- list.files("data/metadata", pattern = "zoomus_recordings__.*\\.csv$", full.names = TRUE)

cat("\nRoster files found:", length(roster_files), "\n")
cat("Zoom recordings files found:", length(zoom_files), "\n")
```

### **Step 1.1: Privacy Level Testing**

Now let's test each privacy level to ensure they work correctly:

```{r test-privacy-levels}
# Function to test privacy levels
test_privacy_level <- function(level, description) {
  cat(sprintf("\n=== Testing %s (%s) ===\n", level, description))
  
      # Set privacy level
    set_privacy_defaults(level)
    
    # Verify privacy level was set
    current_level <- getOption("zoomstudentengagement.privacy_level", "mask")
    cat("Privacy level set to:", current_level, "\n")
    
    # Load a transcript file if available
    transcript_files <- list.files(
      "data/transcripts",
      pattern = "\\.transcript\\.vtt$",
      full.names = TRUE,
      recursive = TRUE
    )
    
    if (length(transcript_files) > 0) {
      transcript_file <- transcript_files[1]
      cat("Testing with:", basename(transcript_file), "\n")
      
      # Calculate metrics with current privacy level
      metrics <- summarize_transcript_metrics(
        transcript_file_path = transcript_file,
        names_exclude = c("dead_air")
      )
    
    # Check what names we see
    unique_names <- unique(metrics$name)
    cat("Unique names found:", length(unique_names), "\n")
    cat("Sample names:", paste(head(unique_names, 5), collapse = ", "), "\n")
    
    # Debug: Show ALL names to see what we're missing
    cat("All unique names:\n")
    for (i in seq_along(unique_names)) {
      cat(sprintf("  %2d: '%s'\n", i, unique_names[i]))
    }
    
    # Check for real names vs masked names
    real_name_pattern <- "^[A-Z][a-z]+(\\s+[A-Z][a-z]+)*$"
    masked_pattern <- "^Student\\s+\\d{2}$"
    
    real_names <- unique_names[grepl(real_name_pattern, unique_names)]
    masked_names <- unique_names[grepl(masked_pattern, unique_names)]
    
    cat("Real names found:", length(real_names), "\n")
    cat("Masked names found:", length(masked_names), "\n")
    
    # Debug: Show which names match each pattern
    cat("Names matching real name pattern:\n")
    for (name in real_names) {
      cat(sprintf("  '%s'\n", name))
    }
    
    cat("Names matching masked pattern:\n")
    for (name in masked_names) {
      cat(sprintf("  '%s'\n", name))
    }
    
    # Show names that don't match either pattern
    unmatched_names <- unique_names[!grepl(real_name_pattern, unique_names) & !grepl(masked_pattern, unique_names)]
    if (length(unmatched_names) > 0) {
      cat("Names that don't match either pattern:\n")
      for (name in unmatched_names) {
        cat(sprintf("  '%s'\n", name))
      }
    }
    
    # Additional check: Test privacy function directly
    cat("\n--- Direct Privacy Function Test ---\n")
    # Create a test dataframe with real names
    test_df <- data.frame(
      name = c("John Smith", "Jane Doe", "Bob Wilson"),
      value = c(1, 2, 3),
      stringsAsFactors = FALSE
    )
    
    # Test privacy function directly
    masked_df <- ensure_privacy(test_df, privacy_level = level)
    direct_names <- unique(masked_df$name)
    cat("Direct privacy test - Sample names:", paste(direct_names, collapse = ", "), "\n")
    
    direct_real <- direct_names[grepl(real_name_pattern, direct_names)]
    direct_masked <- direct_names[grepl(masked_pattern, direct_names)]
    cat("Direct test - Real names:", length(direct_real), "Masked names:", length(direct_masked), "\n")
    
    # Validate expected behavior
    if (level == "ferpa_strict" || level == "ferpa_standard") {
      if (length(real_names) > 0) {
        cat("‚ö†Ô∏è  WARNING: Real names found in", level, "mode\n")
      } else {
        cat("‚úÖ Privacy level", level, "working correctly\n")
      }
    } else if (level == "mask") {
      if (length(masked_names) > 0) {
        cat("‚úÖ Privacy level", level, "working correctly\n")
      } else {
        cat("‚ö†Ô∏è  WARNING: No masked names found in", level, "mode\n")
      }
    } else if (level == "none") {
      if (length(real_names) > 0) {
        cat("‚úÖ Privacy level", level, "working correctly (showing real names)\n")
      } else {
        cat("‚ö†Ô∏è  WARNING: No real names found in", level, "mode\n")
      }
    }
    
    return(metrics)
  } else {
    cat("‚ö†Ô∏è  No transcript files available for testing\n")
    return(NULL)
  }
}

# Test all privacy levels
cat("üîí Testing Privacy Levels\n")
cat("========================\n")

ferpa_strict_metrics <- test_privacy_level("ferpa_strict", "Maximum privacy - masks all names")
ferpa_standard_metrics <- test_privacy_level("ferpa_standard", "Standard privacy - masks students, preserves instructors")
mask_metrics <- test_privacy_level("mask", "Basic masking - masks students, preserves instructors")
none_metrics <- test_privacy_level("none", "No masking - shows all names (use with caution)")

# Reset to default privacy level
set_privacy_defaults("mask")
cat("\n‚úÖ Privacy testing completed. Reset to default 'mask' level.\n")
```

### **Step 1.2: FERPA Compliance Validation**

Let's validate that our outputs are FERPA compliant:

```{r ferpa-validation}
# Function to check for PII in outputs
check_ferpa_compliance <- function(data, description) {
  cat(sprintf("\n=== FERPA Compliance Check: %s ===\n", description))
  
  # Convert data to text for scanning
  data_text <- paste(capture.output(print(data)), collapse = " ")
  
  # Check for PII indicators
  pii_indicators <- c("email", "@", "phone", "address", "ssn", "id", "student_id")
  pii_found <- sapply(pii_indicators, function(x) grepl(x, data_text, ignore.case = TRUE))
  
  if (any(pii_found)) {
    cat("üö® FERPA VIOLATION: PII found in output\n")
    cat("PII indicators found:", paste(names(pii_found[pii_found]), collapse = ", "), "\n")
    return(FALSE)
  } else {
    cat("‚úÖ FERPA compliant: No PII detected\n")
    return(TRUE)
  }
}

# Check FERPA compliance for each privacy level
if (!is.null(ferpa_strict_metrics)) {
  check_ferpa_compliance(ferpa_strict_metrics, "ferpa_strict level")
}

if (!is.null(ferpa_standard_metrics)) {
  check_ferpa_compliance(ferpa_standard_metrics, "ferpa_standard level")
}

if (!is.null(mask_metrics)) {
  check_ferpa_compliance(mask_metrics, "mask level")
}

# Test export security
cat("\n=== Testing Export Security ===\n")
if (!is.null(mask_metrics)) {
  # Test that exported files don't contain real names
  export_file <- "test_privacy_export.csv"
  write.csv(mask_metrics, export_file, row.names = FALSE)
  
  export_content <- readLines(export_file)
  export_has_real_names <- any(sapply(export_content, function(x) grepl("^[A-Z][a-z]+ [A-Z][a-z]+", x)))
  
  if (export_has_real_names) {
    cat("üö® SECURITY ISSUE: Real names found in exported file\n")
  } else {
    cat("‚úÖ Export security: No real names in exported file\n")
  }
  
  # Clean up test file
  unlink(export_file)
}
```

## Step 2: Loading Your Student Roster

Start by loading your student roster:

```{r load-roster}
# Load the student roster
roster_file <- "roster.csv"
roster_path <- file.path("data/metadata", roster_file)

if (file.exists(roster_path)) {
  tryCatch({
    roster <- load_roster(data_folder = "data/metadata", roster_file = roster_file)
    
    # View the roster structure
    head(roster)
    cat("\nRoster dimensions:", nrow(roster), "students\n")
    cat("Roster columns:", paste(names(roster), collapse = ", "), "\n")
    
    # Check for instructor identification
    if ("participant_type" %in% names(roster)) {
      cat("\n=== Instructor Identification in Roster ===\n")
      instructor_count <- sum(roster$participant_type == "instructor", na.rm = TRUE)
      student_count <- sum(roster$participant_type == "enrolled_student", na.rm = TRUE)
      unknown_count <- sum(is.na(roster$participant_type) | roster$participant_type == "unknown", na.rm = TRUE)
      
      cat("Instructors:", instructor_count, "\n")
      cat("Enrolled students:", student_count, "\n")
      cat("Unknown/Unspecified:", unknown_count, "\n")
      
      if (instructor_count > 0) {
        instructors <- roster$preferred_name[roster$participant_type == "instructor"]
        cat("Instructor names:", paste(instructors, collapse = ", "), "\n")
      } else {
        cat("‚ö†Ô∏è  No instructors identified in roster. You may need to add participant_type column.\n")
        cat("Expected format: participant_type should be 'instructor', 'enrolled_student', or 'unknown'\n")
      }
    } else {
      cat("\n‚ö†Ô∏è  No participant_type column found in roster.\n")
      cat("To enable instructor identification, add a participant_type column with values:\n")
      cat("- 'instructor' for instructors (e.g., Conor Healy)\n")
      cat("- 'enrolled_student' for students\n")
      cat("- 'unknown' for unidentified participants\n")
    }
    
  }, error = function(e) {
    cat("‚ö†Ô∏è  Error loading roster:", e$message, "\n")
    cat("Please check that your roster.csv file is properly formatted\n")
  })
} else {
  cat("‚ö†Ô∏è  Roster file not found at:", roster_path, "\n")
  cat("Please add your roster.csv file to data/metadata/\n")
  
  # Create a sample roster template with instructor identification
  cat("\n=== Creating Sample Roster Template ===\n")
  sample_roster <- data.frame(
    preferred_name = c("Conor Healy", "Student One", "Student Two", "Student Three"),
    formal_name = c("Conor Healy", "Student One", "Student Two", "Student Three"),
    student_id = c("INSTRUCTOR", "STU001", "STU002", "STU003"),
    participant_type = c("instructor", "enrolled_student", "enrolled_student", "enrolled_student"),
    stringsAsFactors = FALSE
  )
  
  # Save sample roster
  sample_roster_path <- file.path("data/metadata", "sample_roster_with_instructors.csv")
  write.csv(sample_roster, sample_roster_path, row.names = FALSE)
  cat("Sample roster template created:", sample_roster_path, "\n")
  cat("Edit this file to match your actual student roster and instructor names.\n")
  cat("Make sure to set participant_type to 'instructor' for instructors.\n")
}
```

## Step 3: Loading and Processing Transcript Files

Now let's load and process your Zoom transcripts:

```{r load-transcripts}
# Find a transcript file to work with
transcript_files <- list.files(
  "data/transcripts",
  pattern = "\\.transcript\\.vtt$",
  full.names = TRUE,
  recursive = TRUE
)

if (length(transcript_files) > 0) {
  # Use the first transcript file
  transcript_file <- transcript_files[1]
  cat("Processing transcript:", basename(transcript_file), "\n")
  
  # Load and process the transcript
  transcript_data <- load_zoom_transcript(transcript_file)
  
  # View the structure
  head(transcript_data)
  cat("\nTranscript dimensions:", nrow(transcript_data), "utterances\n")
  cat("Transcript columns:", paste(names(transcript_data), collapse = ", "), "\n")
} else {
  cat("‚ö†Ô∏è  No transcript files found in data/transcripts/\n")
  cat("Please add your Zoom transcript files to data/transcripts/\n")
}
```

## Step 4: Processing Multiple Sessions

If you have multiple sessions, you can process them all at once:

```{r process-multiple}
# Get all transcript files
transcript_files <- list.files(
  "data/transcripts",
  pattern = "\\.transcript\\.vtt$",
  full.names = TRUE,
  recursive = TRUE
)

if (length(transcript_files) > 1) {
  cat("Processing", length(transcript_files), "transcript files...\n")
  
  # Process all transcripts
  all_transcripts <- lapply(transcript_files, function(file) {
    cat("Processing:", basename(file), "\n")
    tryCatch({
      load_zoom_transcript(file)
    }, error = function(e) {
      cat("Error processing", basename(file), ":", e$message, "\n")
      NULL
    })
  })
  
  # Remove any failed transcript loads
  all_transcripts <- all_transcripts[!sapply(all_transcripts, is.null)]
  
  if (length(all_transcripts) > 0) {
    # Combine all transcripts
    combined_transcripts <- dplyr::bind_rows(all_transcripts, .id = "session")
    
    cat("\nCombined data dimensions:", nrow(combined_transcripts), "utterances\n")
    cat("Sessions processed:", length(all_transcripts), "\n")
  } else {
    cat("‚ö†Ô∏è  No transcripts were successfully processed\n")
  }
} else {
  cat("Only one transcript file found. Skipping batch processing.\n")
}
```

## Step 5: Calculating Engagement Metrics

Now let's calculate engagement metrics for each student:

```{r calculate-metrics}
# Calculate metrics for all transcript files
transcript_files <- list.files(
  "data/transcripts",
  pattern = "\\.transcript\\.vtt$",
  full.names = FALSE,
  recursive = TRUE
)

if (length(transcript_files) > 0) {
  cat("Calculating metrics for", length(transcript_files), "transcript files...\n")
  
  metrics <- summarize_transcript_files(
    transcript_file_names = transcript_files,
    data_folder = "data",
    transcripts_folder = "transcripts",
    names_to_exclude = c("dead_air", "Unknown")
  )
  
  # View the metrics
  head(metrics)
  cat("\nMetrics dimensions:", nrow(metrics), "participants\n")
  cat("Metrics columns:", paste(names(metrics), collapse = ", "), "\n")
} else {
  cat("‚ö†Ô∏è  No transcript files found for metrics calculation\n")
}
```

## Step 6: Instructor Identification and Name Matching

This is a critical step that combines instructor identification with privacy-aware name matching. The package now includes sophisticated name matching capabilities that maintain privacy while helping you match Zoom names to your roster.

### **Step 6.1: Instructor Identification**

First, let's identify the instructor(s) in your sessions:

```{r instructor-identification}
# Function to identify instructors from transcript data
identify_instructors <- function(transcript_data, roster_data = NULL) {
  cat("=== Instructor Identification ===\n")
  
  # Get unique speakers from transcript
  speakers <- unique(transcript_data$name)
  cat("Speakers in transcript:", paste(speakers, collapse = ", "), "\n")
  
  # If we have roster data, look for instructor indicators
  if (!is.null(roster_data) && "participant_type" %in% names(roster_data)) {
    instructors_in_roster <- roster_data$preferred_name[roster_data$participant_type == "instructor"]
    cat("Instructors in roster:", paste(instructors_in_roster, collapse = ", "), "\n")
    
    # Find matches between transcript speakers and roster instructors
    instructor_matches <- intersect(speakers, instructors_in_roster)
    if (length(instructor_matches) > 0) {
      cat("‚úÖ Identified instructors:", paste(instructor_matches, collapse = ", "), "\n")
      return(instructor_matches)
    }
  }
  
  # If no roster match, look for common instructor patterns
  instructor_patterns <- c(
    "professor", "prof", "dr", "doctor", "instructor", "teacher", "faculty",
    "conor", "healy", "conor healy"  # Specific to your case
  )
  
  potential_instructors <- character(0)
  for (speaker in speakers) {
    speaker_lower <- tolower(speaker)
    for (pattern in instructor_patterns) {
      if (grepl(pattern, speaker_lower)) {
        potential_instructors <- c(potential_instructors, speaker)
        break
      }
    }
  }
  
  if (length(potential_instructors) > 0) {
    cat("üîç Potential instructors (based on patterns):", paste(potential_instructors, collapse = ", "), "\n")
    cat("Please verify these are correct instructors.\n")
    return(potential_instructors)
  } else {
    cat("‚ö†Ô∏è  No instructors automatically identified.\n")
    cat("You may need to manually specify instructors in the name matching process.\n")
    return(character(0))
  }
}

# Identify instructors if we have transcript and roster data
if (exists("transcript_data") && exists("roster")) {
  instructors <- identify_instructors(transcript_data, roster)
} else if (exists("transcript_data")) {
  instructors <- identify_instructors(transcript_data)
} else {
  cat("‚ö†Ô∏è  Cannot identify instructors - missing transcript data\n")
  instructors <- character(0)
}
```

### **Step 6.2: Privacy-Aware Name Matching Workflow**

Now let's use the new privacy-aware name matching workflow. This is the recommended approach that maintains privacy while helping you match names:

```{r privacy-aware-name-matching}
# Use the safe name matching workflow for privacy-aware matching
if (exists("transcript_data") && exists("roster")) {
  cat("\n=== Privacy-Aware Name Matching ===\n")
  
  # Get the first transcript file for processing
  transcript_files <- list.files(
    "data/transcripts",
    pattern = "\\.transcript\\.vtt$",
    full.names = TRUE,
    recursive = TRUE
  )
  
  if (length(transcript_files) > 0) {
    transcript_file <- transcript_files[1]
    cat("Processing transcript:", basename(transcript_file), "\n")
    
    # Set up privacy defaults for name matching
    set_privacy_defaults(
      privacy_level = "ferpa_standard",  # Standard privacy for matching
      unmatched_names_action = "warn"    # Warn about unmatched names
    )
    
    # Run the safe name matching workflow
    tryCatch({
      cat("Running privacy-aware name matching workflow...\n")
      
      # First, try with default settings (stops on unmatched names)
      result <- safe_name_matching_workflow(
        transcript_file_path = transcript_file,
        roster_data = roster,
        privacy_level = "ferpa_standard",
        unmatched_names_action = "warn"  # This will warn and guide through matching
      )
      
      cat("‚úÖ Name matching workflow completed successfully!\n")
      
      # Show matching results
      if (!is.null(result) && nrow(result) > 0) {
        cat("\nName Matching Results:\n")
        cat("Total participants:", nrow(result), "\n")
        
        # Count by participant type
        if ("participant_type" %in% names(result)) {
          type_counts <- table(result$participant_type)
          cat("Participant types:\n")
          for (type in names(type_counts)) {
            cat("  ", type, ":", type_counts[type], "\n")
          }
        }
        
        # Show matched vs unmatched
        if ("is_matched" %in% names(result)) {
          matched_count <- sum(result$is_matched, na.rm = TRUE)
          unmatched_count <- sum(!result$is_matched, na.rm = TRUE)
          cat("Matched names:", matched_count, "\n")
          cat("Unmatched names:", unmatched_count, "\n")
        }
        
        # Store the result for later use
        clean_metrics <- result
        
      } else {
        cat("‚ö†Ô∏è  No results returned from name matching workflow\n")
      }
      
    }, error = function(e) {
      cat("‚ùå Error in name matching workflow:", e$message, "\n")
      cat("This may indicate unmatched names that need manual resolution.\n")
      
      # Try to provide guidance for manual matching
      cat("\n=== Manual Name Matching Guidance ===\n")
      cat("If you have unmatched names, you can:\n")
      cat("1. Use prompt_name_matching() to create a lookup template\n")
      cat("2. Edit the template manually with correct name mappings\n")
      cat("3. Re-run the workflow with the updated mappings\n")
    })
    
  } else {
    cat("‚ö†Ô∏è  No transcript files found for name matching\n")
  }
} else {
  cat("‚ö†Ô∏è  Cannot perform name matching - missing transcript data or roster\n")
}
```

### **Step 6.3: Manual Name Matching (if needed)**

If the automated workflow doesn't match all names, you can use the manual approach:

```{r manual-name-matching}
# If we need manual name matching, use the prompt_name_matching function
if (exists("transcript_data") && (!exists("clean_metrics") || nrow(clean_metrics) == 0)) {
  cat("\n=== Manual Name Matching Setup ===\n")
  
  # Extract names from transcript
  transcript_names <- unique(transcript_data$name)
  
  # Use prompt_name_matching to create a lookup template
  tryCatch({
    cat("Creating name matching template...\n")
    
    lookup_file <- prompt_name_matching(
      unmatched_names = transcript_names,
      privacy_level = "ferpa_standard",
      data_folder = "data",
      include_instructions = TRUE
    )
    
    cat("‚úÖ Name matching template created:", lookup_file, "\n")
    cat("Please edit this file to add your name mappings, then reload it.\n")
    cat("Instructions are included in the template file.\n")
    
  }, error = function(e) {
    cat("‚ùå Error creating name matching template:", e$message, "\n")
  })
}
```

### **Step 6.4: Loading Custom Name Mappings**

If you've created custom name mappings, load them here:

```{r load-custom-mappings}
# Check for custom name mappings
mapping_files <- list.files(
  "data/metadata",
  pattern = ".*names.*lookup.*csv$",
  full.names = TRUE
)

if (length(mapping_files) > 0) {
  cat("\n=== Loading Custom Name Mappings ===\n")
  
  # Use the most recent mapping file
  mapping_file <- mapping_files[length(mapping_files)]
  cat("Loading mappings from:", basename(mapping_file), "\n")
  
  tryCatch({
    custom_mappings <- read.csv(mapping_file, stringsAsFactors = FALSE)
    
    cat("Loaded", nrow(custom_mappings), "name mappings\n")
    
    # Show a preview of the mappings
    if (nrow(custom_mappings) > 0) {
      cat("Mapping preview:\n")
      print(head(custom_mappings))
    }
    
    # Apply mappings to transcript data if available
    if (exists("transcript_data")) {
      clean_transcript <- transcript_data %>%
        left_join(custom_mappings, by = c("name" = "transcript_name")) %>%
        mutate(
          clean_name = coalesce(preferred_name, name),
          is_matched = !is.na(preferred_name) & preferred_name != name
        )
      
      # Summary of matching success
      if ("is_matched" %in% names(clean_transcript)) {
        matched_count <- sum(clean_transcript$is_matched, na.rm = TRUE)
        total_count <- nrow(clean_transcript)
        cat("Applied mappings:", matched_count, "of", total_count, "utterances matched\n")
      }
      
      # Store for later use
      clean_metrics <- clean_transcript
    }
    
  }, error = function(e) {
    cat("‚ùå Error loading custom mappings:", e$message, "\n")
  })
} else {
  cat("No custom name mapping files found.\n")
}
```

## Step 7: Analyzing Participation Patterns

Now let's analyze participation patterns to understand engagement:

```{r analyze-patterns}
if (exists("clean_metrics") && nrow(clean_metrics) > 0) {
  # Create a summary by student
  student_summary <- clean_metrics %>%
    group_by(student_name) %>%
    summarise(
      total_utterances = sum(n, na.rm = TRUE),
      total_duration = sum(duration, na.rm = TRUE),
      total_words = sum(wordcount, na.rm = TRUE),
      avg_words_per_minute = mean(wpm, na.rm = TRUE),
      participation_rate = total_utterances / nrow(clean_metrics) * 100
    ) %>%
    arrange(desc(total_utterances))
  
  # View the summary
  head(student_summary, 10)
  
  # Basic statistics
  cat("\nParticipation Statistics:\n")
  participation_stats <- student_summary %>%
    summarise(
      mean_utterances = mean(total_utterances, na.rm = TRUE),
      median_utterances = median(total_utterances, na.rm = TRUE),
      sd_utterances = sd(total_utterances, na.rm = TRUE),
      min_utterances = min(total_utterances, na.rm = TRUE),
      max_utterances = max(total_utterances, na.rm = TRUE)
    )
  print(participation_stats)
} else {
  cat("‚ö†Ô∏è  Cannot analyze participation patterns - missing clean metrics data\n")
}
```

## Step 8: Visualizing Participation

Create visualizations to understand participation patterns:

```{r visualize-participation}
if (exists("student_summary") && nrow(student_summary) > 0) {
  # Plot participation by utterance count
  p1 <- ggplot(student_summary, aes(x = reorder(student_name, total_utterances), y = total_utterances)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    coord_flip() +
    labs(
      title = "Student Participation by Utterance Count",
      x = "Student Name",
      y = "Number of Utterances"
    ) +
    theme_minimal()
  
  print(p1)
  
  # Plot participation by duration
  p2 <- ggplot(student_summary, aes(x = reorder(student_name, total_duration), y = total_duration / 60)) +
    geom_bar(stat = "identity", fill = "darkgreen") +
    coord_flip() +
    labs(
      title = "Student Participation by Speaking Time",
      x = "Student Name",
      y = "Speaking Time (minutes)"
    ) +
    theme_minimal()
  
  print(p2)
  
  # Save plots
  ggsave("participation_by_utterances.png", p1, width = 10, height = 8)
  ggsave("participation_by_duration.png", p2, width = 10, height = 8)
  
  cat("Plots saved as:\n")
  cat("- participation_by_utterances.png\n")
  cat("- participation_by_duration.png\n")
} else {
  cat("‚ö†Ô∏è  Cannot create visualizations - missing student summary data\n")
}
```

## Step 9: Identifying Participation Gaps

Look for students who might need encouragement to participate:

```{r identify-gaps}
if (exists("student_summary") && nrow(student_summary) > 0) {
  # Identify students with low participation
  median_utterances <- median(student_summary$total_utterances, na.rm = TRUE)
  low_participation <- student_summary %>%
    filter(total_utterances < median_utterances) %>%
    arrange(total_utterances)
  
  cat("Students with below-median participation:\n")
  print(low_participation[, c("student_name", "total_utterances", "total_duration")])
  
  # Create participation categories
  participation_categories <- student_summary %>%
    mutate(
      participation_level = case_when(
        total_utterances >= quantile(total_utterances, 0.75, na.rm = TRUE) ~ "High",
        total_utterances >= quantile(total_utterances, 0.25, na.rm = TRUE) ~ "Medium",
        TRUE ~ "Low"
      )
    )
  
  # Summary by participation level
  level_summary <- participation_categories %>%
    group_by(participation_level) %>%
    summarise(
      count = n(),
      percentage = n() / nrow(participation_categories) * 100
    )
  
  cat("\nParticipation Level Distribution:\n")
  print(level_summary)
} else {
  cat("‚ö†Ô∏è  Cannot identify participation gaps - missing student summary data\n")
}
```

## Step 10: Creating Actionable Insights

Generate insights that can help improve equitable participation:

```{r actionable-insights}
cat("=== RECOMMENDATIONS FOR EQUITABLE PARTICIPATION ===\n")
cat("1. Students with low participation may benefit from:\n")
cat("   - Direct invitations to contribute\n")
cat("   - Smaller group discussions\n")
cat("   - Alternative participation methods (chat, polls)\n\n")

cat("2. Consider implementing:\n")
cat("   - Structured discussion protocols\n")
cat("   - Think-pair-share activities\n")
cat("   - Anonymous participation options\n\n")

cat("3. Monitor participation patterns over time to:\n")
cat("   - Track improvement in engagement\n")
cat("   - Identify effective interventions\n")
cat("   - Ensure all students feel included\n\n")

if (exists("student_summary") && nrow(student_summary) > 0) {
  cat("4. Specific recommendations for your class:\n")
  cat("   - Total students analyzed:", nrow(student_summary), "\n")
  cat("   - Average utterances per student:", round(mean(student_summary$total_utterances, na.rm = TRUE), 1), "\n")
  cat("   - Students with below-average participation:", sum(student_summary$total_utterances < mean(student_summary$total_utterances, na.rm = TRUE)), "\n")
}
```

## Step 11: Final Privacy Validation

Before saving your analysis, let's do a final privacy check to ensure no sensitive data is exposed:

```{r final-privacy-check}
# Function to scan for real names in final outputs
scan_for_real_names <- function(data, description) {
  cat(sprintf("\n=== Final Privacy Scan: %s ===\n", description))
  
  # Convert data to text
  data_text <- paste(capture.output(print(data)), collapse = " ")
  
      # Look for real name patterns
    real_name_pattern <- "\\b[A-Z][a-z]+(\\s+[A-Z][a-z]+)*\\b"
  real_names <- unlist(regmatches(data_text, gregexpr(real_name_pattern, data_text)))
  
  # Filter out common words that might match
  common_words <- c(
    "Test Report", "Real World", "Test Date", "Test Results", "Test Summary",
    "Package Version", "Total Tests", "Success Rate", "Detailed Results",
    "Status Started", "Status Passed", "Status Failed", "Timestamp Details",
    "Error Handling", "Privacy Features", "Recommendations Review"
  )
  real_names <- real_names[!real_names %in% common_words]
  
  if (length(real_names) > 0) {
    cat("üö® PRIVACY ISSUE: Real names found in final output\n")
    cat("Names found:", paste(unique(real_names), collapse = ", "), "\n")
    cat("This violates FERPA compliance requirements.\n")
    return(FALSE)
  } else {
    cat("‚úÖ Privacy maintained: No real names in final output\n")
    return(TRUE)
  }
}

# Check final outputs for privacy
if (exists("clean_metrics")) {
  scan_for_real_names(clean_metrics, "Clean Metrics")
}

if (exists("student_summary")) {
  scan_for_real_names(student_summary, "Student Summary")
}

cat("\n‚úÖ Final privacy validation completed.\n")
```

## Step 12: Saving Your Analysis

Save your processed data for future reference:

```{r save-analysis}
# Create output directory
if (!dir.exists("outputs")) {
  dir.create("outputs")
}

# Save the clean metrics
if (exists("clean_metrics")) {
  write_engagement_metrics(clean_metrics, "outputs/clean_engagement_metrics.csv", comments_format = "text")
  cat("Saved: outputs/clean_engagement_metrics.csv\n")
}

# Save the student summary
if (exists("student_summary")) {
  write_engagement_metrics(student_summary, "outputs/student_participation_summary.csv")
  cat("Saved: outputs/student_participation_summary.csv\n")
}

# Save the name mappings
if (exists("custom_mappings")) {
  write_engagement_metrics(custom_mappings, "outputs/name_mappings.csv")
  cat("Saved: outputs/name_mappings.csv\n")
}

cat("\nAnalysis files saved to outputs/ directory\n")
```

## Best Practices and Tips

### Privacy and FERPA Compliance
- **Always test privacy levels** before working with real data
- **Use appropriate privacy levels** for your use case:
  - `ferpa_strict` for maximum privacy (recommended for research)
  - `ferpa_standard` for standard educational use
  - `mask` for basic privacy protection
  - `none` only for temporary matching (never for final outputs)
- **Validate privacy compliance** at each step
- **Never commit or share outputs** containing real names
- **Document your privacy approach** for institutional review

### Data Organization
- Keep your transcript files organized by date/session
- Maintain a consistent naming convention
- Back up your original data files
- Document any manual name mappings

### Ethical Considerations
- Use this data to promote equitable participation, not surveillance
- Focus on group patterns rather than individual performance
- Respect student privacy and preferences
- Share insights constructively with students when appropriate

### Common Pitfalls to Avoid
- Don't assume low participation means disengagement
- Consider cultural and personal communication preferences
- Remember that quality of participation matters more than quantity
- Avoid making assumptions about student abilities based on participation

### Interpreting Results
- Look for patterns, not individual judgments
- Consider context (class size, format, topic)
- Use data to inform teaching strategies, not student evaluation
- Focus on creating inclusive learning environments

## Next Steps

This analysis provides a foundation for understanding participation patterns. Consider:

1. **Regular monitoring**: Track participation patterns over the semester
2. **Intervention strategies**: Implement targeted approaches for low-participation students
3. **Student feedback**: Ask students about their participation preferences
4. **Pedagogical adjustments**: Modify teaching strategies based on insights
5. **Continuous improvement**: Refine your analysis approach over time

Remember: The goal is to create an inclusive learning environment where all students feel comfortable and encouraged to participate in ways that work for them. 